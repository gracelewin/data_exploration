{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4c44c8",
   "metadata": {},
   "source": [
    "## MOSAIKS feature extraction\n",
    "\n",
    "This tutorial demonstrates the **MOSAIKS** method for extracting _feature vectors_ from satellite imagery patches for use in downstream modeling tasks. It will show:\n",
    "- How to extract 1km$^2$ patches ofLandsat 8 multispectral imagery for a list of latitude, longitude points\n",
    "- How to extract summary features from each of these imagery patches\n",
    "- How to use the summary features in a linear model of the population density at each point\n",
    "\n",
    "### Background\n",
    "\n",
    "Consider the case where you have a dataset of latitude and longitude points assosciated with some dependent variable (for example: population density, weather, housing prices, biodiversity) and, potentially, other independent variables. You would like to model the dependent variable as a function of the independent variables, but instead of including latitude and longitude directly in this model, you would like to include some high dimensional representation of what the Earth looks like at that point (that hopefully explains some of the variance in the dependent variable!). From the computer vision literature, there are various [representation learning techniques](https://en.wikipedia.org/wiki/Feature_learning) that can be used to do this, i.e. extract _features vectors_ from imagery. This notebook gives an implementation of the technique described in [Rolf et al. 2021](https://www.nature.com/articles/s41467-021-24638-z), \"A generalizable and accessible approach to machine learning with global satellite imagery\" called Multi-task Observation using Satellite Imagery & Kitchen Sinks (**MOSAIKS**). For more information about **MOSAIKS** see the [project's webpage](http://www.globalpolicy.science/mosaiks).\n",
    "\n",
    "\n",
    "**Notes**:\n",
    "- If you're running this on the [Planetary Computer Hub](http://planetarycomputer.microsoft.com/compute), make sure to choose the **GPU - PyTorch** profile when presented with the form to choose your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d60ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/geopandas/dask-geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "\n",
    "RASTERIO_BEST_PRACTICES = dict(  # See https://github.com/pangeo-data/cog-best-practices\n",
    "    CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\",\n",
    "    GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "    AWS_NO_SIGN_REQUEST=\"YES\",\n",
    "    GDAL_MAX_RAW_BLOCK_CACHE_SIZE=\"200000000\",\n",
    "    GDAL_SWATH_SIZE=\"200000000\",\n",
    "    VSI_CURL_CACHE_SIZE=\"200000000\",\n",
    ")\n",
    "os.environ.update(RASTERIO_BEST_PRACTICES)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import rasterio\n",
    "import rasterio.warp\n",
    "import rasterio.mask\n",
    "import shapely.geometry\n",
    "import geopandas\n",
    "import dask_geopandas\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from dask.distributed import Client\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=LinAlgWarning, module=\"sklearn\")\n",
    "\n",
    "import pystac_client\n",
    "import planetary_computer as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e372135a",
   "metadata": {},
   "source": [
    "First we define the pytorch model that we will use to extract the features and a helper method. The **MOSAIKS** methodology describes several ways to do this and we use the simplest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(input_img, model, device):\n",
    "    \"\"\"Helper method for running an image patch through the model.\n",
    "\n",
    "    Args:\n",
    "        input_img (np.ndarray): Image in (C x H x W) format with a dtype of uint8.\n",
    "        model (torch.nn.Module): Feature extractor network\n",
    "    \"\"\"\n",
    "    assert len(input_img.shape) == 3\n",
    "    input_img = torch.from_numpy(input_img / 255.0).float()\n",
    "    input_img = input_img.to(device)\n",
    "    with torch.no_grad():\n",
    "        feats = model(input_img.unsqueeze(0)).cpu().numpy()\n",
    "    return feats\n",
    "\n",
    "\n",
    "class RCF(nn.Module):\n",
    "    \"\"\"A model for extracting Random Convolution Features (RCF) from input imagery.\"\"\"\n",
    "\n",
    "    def __init__(self, num_features=16, kernel_size=3, num_input_channels=1):   # ------------------------------------------------------------- Input channels\n",
    "        super(RCF, self).__init__()\n",
    "\n",
    "        # We create `num_features / 2` filters so require `num_features` to be divisible by 2\n",
    "        assert num_features % 2 == 0\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            num_input_channels,\n",
    "            num_features // 2,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=1.0)\n",
    "        nn.init.constant_(self.conv1.bias, -1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1a = F.relu(self.conv1(x), inplace=True)\n",
    "        x1b = F.relu(-self.conv1(x), inplace=True)\n",
    "\n",
    "        x1a = F.adaptive_avg_pool2d(x1a, (1, 1)).squeeze()\n",
    "        x1b = F.adaptive_avg_pool2d(x1b, (1, 1)).squeeze()\n",
    "\n",
    "        if len(x1a.shape) == 1:  # case where we passed a single input\n",
    "            return torch.cat((x1a, x1b), dim=0)\n",
    "        elif len(x1a.shape) == 2:  # case where we passed a batch of > 1 inputs\n",
    "            return torch.cat((x1a, x1b), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f303c0",
   "metadata": {},
   "source": [
    "Next, we initialize the model and pytorch components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b896be",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 2048\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = RCF(num_features).eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c804888",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read dataset of (lat, lon) points and corresponding labels\n",
    "Zambia:   1997-2015  \n",
    "Tanzania: 2003-2010  \n",
    "Nigeria:  1995-2006  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052a0c3-a454-4b39-bbc0-3d9747a93e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2013\n",
    "adm_level = \"adm1\"\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb26116-c8a1-4554-9cdb-f1d03671b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Data\n",
    "gdf_crop = geopandas.read_file(\"data/unified_crop_data.gpkg\")\n",
    "\n",
    "# Filter for 1 Country\n",
    "gdf_crop = gdf_crop[gdf_crop.adm0 == 'zambia']\n",
    "\n",
    "# Filter for 1 year but keep geometry without crop data\n",
    "gdf_crop = gdf_crop[(gdf_crop.year == year) | (np.isnan(gdf_crop.year))]\n",
    "\n",
    "# find the bounds of your geodataframe\n",
    "x_min, y_min, x_max, y_max = gdf_crop.total_bounds\n",
    "\n",
    "# set sample size (number of points inside bounding box)\n",
    "# this will be reduced to only points inside the country\n",
    "n = 2000\n",
    "\n",
    "# generate random data within the bounds\n",
    "x = np.random.uniform(x_min, x_max, n)\n",
    "y = np.random.uniform(y_min, y_max, n)\n",
    "\n",
    "# convert them to a points GeoSeries\n",
    "gdf_points = geopandas.GeoSeries(geopandas.points_from_xy(x, y))\n",
    "\n",
    "# only keep those points within polygons\n",
    "gdf_points = gdf_points[gdf_points.within(gdf_crop.unary_union)]\n",
    "\n",
    "# make points GeoSeries into GeoDataFrame\n",
    "gdf_points = geopandas.GeoDataFrame(gdf_points).rename(columns={0:'geometry'}).set_geometry('geometry')\n",
    "\n",
    "# Make blank GeoDataFrame\n",
    "gdf = geopandas.GeoDataFrame()\n",
    "\n",
    "# Extract lon, lat, and geometry values and assign to columns\n",
    "gdf['lon'] = gdf_points['geometry'].x\n",
    "gdf['lat'] = gdf_points['geometry'].y\n",
    "gdf['geometry'] = gdf_points['geometry']\n",
    "\n",
    "# Set CRS\n",
    "gdf = gdf.set_crs('EPSG:4326')\n",
    "\n",
    "# Also make a regular dataframe\n",
    "points = pd.DataFrame(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6642ee-5bb3-41a4-98f9-824745749065",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e2434-d02e-4d90-8bd2-97b2a40ec24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf_crop.plot(\n",
    "    ax = ax\n",
    "    , color = \"blue\"\n",
    "    , edgecolor = 'black'\n",
    "    , alpha = .25\n",
    ")\n",
    "gdf.plot(ax = ax)\n",
    "ax.grid(False)\n",
    "ctx.add_basemap(ax, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf320a80",
   "metadata": {},
   "source": [
    "Get rid of points with nodata population values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e52c4e",
   "metadata": {},
   "source": [
    "### Extract features from the imagery around each point\n",
    "\n",
    "We need to find a suitable Sentinel 2 scene for each point. As usual, we'll use `pystac-client` to search for items matching some conditions, but we don't just want do make a `.search()` call for each of the 67,968 remaining points. Each HTTP request is relatively slow. Instead, we will *batch* or points and search *in parallel*.\n",
    "\n",
    "We need to be a bit careful with how we batch up our points though. Since a single Sentinel 2 scene will cover many points, we want to make sure that points which are spatially close together end up in the same batch. In short, we need to spatially partition the dataset. This is implemented in `dask-geopandas`.\n",
    "\n",
    "So the overall workflow will be\n",
    "\n",
    "1. Find an appropriate STAC item for each point (in parallel, using the spatially partitioned dataset)\n",
    "2. Feed the points and STAC items to a custom Dataset that can read imagery given a point and the URL of a overlapping S2 scene\n",
    "3. Use a custom Dataloader, which uses our Dataset, to feed our model imagery and save the corresponding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ee566-4819-416b-a194-57303f78cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPARTITIONS = 250\n",
    "\n",
    "ddf = dask_geopandas.from_geopandas(gdf, npartitions=1)\n",
    "hd = ddf.hilbert_distance().compute()\n",
    "gdf[\"hd\"] = hd\n",
    "gdf = gdf.sort_values(\"hd\")\n",
    "gdf = gdf.reset_index()\n",
    "\n",
    "dgdf = dask_geopandas.from_geopandas(gdf, npartitions=NPARTITIONS, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ae053",
   "metadata": {},
   "source": [
    "We'll write a helper function that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55349b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(points):\n",
    "    \"\"\"\n",
    "    Find a STAC item for points in the `points` DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : geopandas.GeoDataFrame\n",
    "        A GeoDataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        A new geopandas.GeoDataFrame with a `stac_item` column containing the STAC\n",
    "        item that covers each point.\n",
    "    \"\"\"\n",
    "    intersects = shapely.geometry.mapping(points.unary_union.convex_hull)\n",
    "\n",
    "    search_start = f\"{year}-01-01\"\n",
    "    search_end = f\"{year}-12-31\"\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "    )\n",
    "\n",
    "    # The time frame in which we search for non-cloudy imagery\n",
    "    search = catalog.search(\n",
    "        collections=[\"landsat-8-c2-l2\"],  # \"landsat-8-c2-l2\"   \"sentinel-2-l2a\"\n",
    "        intersects=intersects,\n",
    "        datetime=[search_start, search_end],\n",
    "        query={\"eo:cloud_cover\": {\"lt\": 10}},\n",
    "        limit=500,\n",
    "    )\n",
    "    ic = search.get_all_items_as_dict()\n",
    "\n",
    "    features = ic[\"features\"]\n",
    "    features_d = {item[\"id\"]: item for item in features}\n",
    "\n",
    "    data = {\n",
    "        \"eo:cloud_cover\": [],\n",
    "        \"geometry\": [],\n",
    "    }\n",
    "\n",
    "    index = []\n",
    "\n",
    "    for item in features:\n",
    "        data[\"eo:cloud_cover\"].append(item[\"properties\"][\"eo:cloud_cover\"])\n",
    "        data[\"geometry\"].append(shapely.geometry.shape(item[\"geometry\"]))\n",
    "        index.append(item[\"id\"])\n",
    "\n",
    "    items = geopandas.GeoDataFrame(data, index=index, geometry=\"geometry\").sort_values(\n",
    "        \"eo:cloud_cover\"\n",
    "    )\n",
    "    point_list = points.geometry.tolist()\n",
    "\n",
    "    point_items = []\n",
    "    for point in point_list:\n",
    "        covered_by = items[items.covers(point)]\n",
    "        if len(covered_by):\n",
    "            point_items.append(features_d[covered_by.index[0]])\n",
    "        else:\n",
    "            # There weren't any scenes matching our conditions for this point (too cloudy)\n",
    "            point_items.append(None)\n",
    "\n",
    "    return points.assign(stac_item=point_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with Client(n_workers=16) as client:\n",
    "    print(client.dashboard_link)\n",
    "    meta = dgdf._meta.assign(stac_item=[])\n",
    "    df2 = dgdf.map_partitions(query, meta=meta).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ea985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eab13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.dropna(subset=[\"stac_item\"])\n",
    "\n",
    "matching_urls =(\n",
    "    [pc.sign(item[\"assets\"][\"SR_B1\"][\"href\"]) for item in df3.stac_item.tolist()] +\n",
    "    [pc.sign(item[\"assets\"][\"SR_B2\"][\"href\"]) for item in df3.stac_item.tolist()] +\n",
    "    [pc.sign(item[\"assets\"][\"SR_B3\"][\"href\"]) for item in df3.stac_item.tolist()]\n",
    ")\n",
    "\n",
    "points = df3[[\"lon\", \"lat\"]].to_numpy()\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26646f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, points, fns, buffer=500):\n",
    "        self.points = points\n",
    "        self.fns = fns\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.points.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        lon, lat = self.points[idx]\n",
    "        fn = self.fns[idx]\n",
    "\n",
    "        if fn is None:\n",
    "            return None\n",
    "        else:\n",
    "            point_geom = shapely.geometry.mapping(shapely.geometry.Point(lon, lat))\n",
    "\n",
    "            with rasterio.Env():\n",
    "                with rasterio.open(fn, \"r\") as f:\n",
    "                    point_geom = rasterio.warp.transform_geom(\n",
    "                        \"epsg:4326\", f.crs.to_string(), point_geom\n",
    "                    )\n",
    "                    point_shape = shapely.geometry.shape(point_geom)\n",
    "                    mask_shape = point_shape.buffer(self.buffer).envelope\n",
    "                    mask_geom = shapely.geometry.mapping(mask_shape)\n",
    "                    try:\n",
    "                        out_image, out_transform = rasterio.mask.mask(\n",
    "                            f, [mask_geom], crop=True\n",
    "                        )\n",
    "                    except ValueError as e:\n",
    "                        if \"Input shapes do not overlap raster.\" in str(e):\n",
    "                            return None\n",
    "\n",
    "            out_image = out_image / 255.0\n",
    "            out_image = torch.from_numpy(out_image).float()\n",
    "            return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(points, matching_urls)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=os.cpu_count() ,\n",
    "    collate_fn=lambda x: x,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = np.zeros((points.shape[0], num_features), dtype=float)\n",
    "\n",
    "tic = time.time()\n",
    "i = 0\n",
    "for images in dataloader:\n",
    "    for image in images:\n",
    "\n",
    "        if image is not None:\n",
    "            # Edit this below to reflect landsat data\n",
    "            \n",
    "            # A full image should be ~101x101 pixels (i.e. ~1km^2 at a 30m/px spatial\n",
    "            # resolution), however we can receive smaller images if an input point\n",
    "            # happens to be at the edge of a landsat scene (a literal edge case). To deal\n",
    "            # with these (edge) cases we crudely drop all images where the spatial\n",
    "            # dimensions aren't both greater than 20 pixels.\n",
    "            if image.shape[1] >= 20 and image.shape[2] >= 20:\n",
    "                image = image.to(device)\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "            else:\n",
    "                # this happens if the point is close to the edge of a scene\n",
    "                # (one or both of the spatial dimensions of the image are very small)\n",
    "                pass\n",
    "        else:\n",
    "            pass  # this happens if we do not find a S2 scene for some point\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\n",
    "                f\"{i}/{points.shape[0]} -- {i / points.shape[0] * 100:0.2f}%\"\n",
    "                + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "            )\n",
    "            tic = time.time()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e337d82-8fe4-4928-8344-e3be39e92b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b86bd-303b-45d6-b389-d3ee258457be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = pd.DataFrame(x_all)\n",
    "x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eefbf7-a054-4591-a978-37bb5d59e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35073da-30cc-4fcd-8ec0-fa25c7c5a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_features = gdf.join(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2d3ea-d728-4304-82d7-b54de39e3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_features = gdf_features.drop(['index', 'lon', 'lat', 'hd'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8aee3-9ea1-476d-8804-a24ceb9ca54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306246ed-cc5e-460b-b925-4bcaa5c8e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = range(0, num_features)\n",
    "gdf_features_long = pd.melt(gdf_features,  \n",
    "                            id_vars=['geometry'], \n",
    "                            value_vars=cols, \n",
    "                            var_name = 'feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137565be-1157-4ac5-86b3-a6bdaa3a9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = gdf_crop.sjoin(gdf_features_long, how = 'right', predicate = 'intersects')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42113f2e-6734-4e21-899a-8773e51f412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_summary = features.groupby([adm_level, 'year', 'feature']).agg({'value': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9d56b-e6b2-4744-9aad-9cab92beaf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_summary = features_summary.reset_index()\n",
    "features_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30f280-2a41-4c50-ae4b-df81bbdc0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_summary_wide = features_summary.pivot(index = [adm_level, \"year\"], columns='feature', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc96a2-8fb9-4b68-913a-6073d96a8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_summary_wide = features_summary_wide.reset_index().rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24e61f-f792-4cc8-855b-9aface0589a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_summary_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf81e3-5952-40bf-8510-a048c8ae28a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
